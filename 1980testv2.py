# -*- coding: utf-8 -*-
"""1980_Emotion-DualDriver.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OM961UxxOErds4kv9JBNFc30a7lrowcD
"""

#mount drive
from google.colab import drive
drive.mount('/content/drive')

#install librosa
!pip install librosa

#install shap
!pip install shap

import librosa
from librosa import display
import numpy as np
import os
import pandas as pd
import glob
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import tensorflow as tf
from matplotlib.pyplot import specgram
import tensorflow.keras
from tensorflow.keras.preprocessing import sequence
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding
from tensorflow.keras.layers import LSTM
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Input, Flatten, Dropout, Activation
from tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.metrics import confusion_matrix
from sklearn import preprocessing
import sys
import shap
import pickle

def DecisionTree(X_train, X_test, y_train, y_test):

  dtree = DecisionTreeClassifier()
  dtree.fit(X_train, y_train)
  predictions = dtree.predict(X_test)
  print(classification_report(y_test,predictions))

  return dtree

def RandomForest(X_train, X_test, y_train, y_test):

  rforest = RandomForestClassifier(criterion="gini", max_depth=10, max_features="log2", 
                                   max_leaf_nodes = 100, min_samples_leaf = 3, min_samples_split = 20, 
                                   n_estimators= 22000, random_state= 5)

  rforest.fit(X_train, y_train)
  predictions = rforest.predict(X_test)
  print(classification_report(y_test,predictions))

  return rforest

#Dataset defaults to ravdess
dataset_name = 'ravdess'
if(sys.argv[1] == 'emodb'):
  dataset_name = 'emodb'
elif(sys.argv[1] == 'EMOVO'):
  dataset_name = 'EMOVO'
elif(sys.argv[1] == 'savee'):
  dataset_name = 'savee'

def NueralNetwork(X_train, X_test, y_train, y_test):

  x_traincnn = np.expand_dims(X_train, axis=2)
  x_testcnn = np.expand_dims(X_test, axis=2)

  #Begin constructing model layers
  model = Sequential()

  model.add(Conv1D(128, 5,padding='same',
                   input_shape=(40,1)))
  model.add(Activation('relu'))
  model.add(Dropout(0.1))
  model.add(MaxPooling1D(pool_size=(8)))
  model.add(Conv1D(128, 5,padding='same',))
  model.add(Activation('relu'))
  model.add(Dropout(0.1))
  model.add(Flatten())

  #Change the final decision
  classnum = 10
  if(dataset_name == 'ravdess'):
    classnum = 8
  model.add(Dense(classnum))
  model.add(Activation('softmax'))
  opt = tf.keras.optimizers.RMSprop(learning_rate=0.00005, rho=0.9, epsilon=None, decay=0.0)

  model.summary()

  model.compile(loss='sparse_categorical_crossentropy',
                optimizer=opt,
                metrics=['accuracy'])

  #Due to differences in the dataset, each set requires a different onehot label encoder
  le = preprocessing.LabelEncoder()
  if(dataset_name == 'ravdess'):
    le.fit(["01", "02", "03", "04", "05", "06", "07", "08"])
  #1) anger; 2) boredom; 3) anxiety; 4) happiness; 5) sadness; 6) disgust; and 7) neutral

  #Annoyingly all of these are the first letter of the German words for these emotions
  elif(dataset_name == 'emodb'): 
    le.fit(["F", "N", "W", "T", "A", "L", "E"])
    
  #Italian dataset, emotions are first three letters of: (neutral, disgust, joy, fear, anger, surprise, sadness)
  elif(dataset_name == 'EMOVO'): 
    le.fit(["dis", "gio", "nue", "pau", "rab", "sor", "tri"])

  #The letters 'a', 'd', 'f', 'h', 'n', 'sa' and 'su' represent 'anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness' and 'surprise' emotion classes respectively. 
  elif(dataset_name == 'savee'): 
    le.fit(["a", "d", "f", "h", "n", "sa", "su"])

  y_train_encoded = le.transform(y_train)
  y_test_encoded = le.transform(y_test)

  cnnhistory=model.fit(x_traincnn, y_train_encoded, batch_size=16, epochs=1000, validation_data=(x_testcnn, y_test_encoded))

  return model, cnnhistory, x_testcnn

def explainTree(model,X):
  shap.initjs()
  explainer = shap.TreeExplainer(model)
  #emotional subset for X
  shap_values = explainer.shap_values(X)
  shap.summary_plot(shap_values, features=X, class_names=model.classes_)

def explainNN(model,xTrain,xTest):
  shap.initjs()
  explainer = shap.KernelExplainer(model.predict,xTrain)
  shap_values = explainer.shap_values(xTest,nsamples=100)
  shap.summary_plot(shap_values, class_names=model.classes_)

sys.argv[1] = 'ravdess'
sys.argv[2] = 'all'

if (sys.argv[1] not in ['ravdess', 'emodb', 'EMOVO', 'savee', '']):
  raise Exception("Argument Error: Please select an appropriate dataset: [ravdess, emodb, EMOVO, savee]")

if (sys.argv[2] not in ['all', 'tree', 'forest', 'NN']):
  raise Exception("Argument Error: Please select the models you would like to run: [decision tree (tree), random forest (forest), nueral network (NN), or all three")

path = '/content/drive/My Drive/Senior/1980/' + dataset_name
lst = []

#decide whether to use an already pickled list, pickle a new list, or run without pickling at all
#pickle - pickle a new list
#pickled - use an already pickled list
#pickleless - run without pickling
pickle = 'pickleless'
if(len(sys.argv) == 4):
  if(sys.argv[3] == 'pickle'):
    pickle = 'pickle'
  elif(sys.argv[3] == 'pickled'):
    pickle = 'pickled'

if(pickle == 'pickleless' or pickle == 'pickle'):
  for subdir, dirs, files in os.walk(path):
    for file in files:
        try:
          #Load librosa array, obtain mfcss, store the file and the mcss information in a new array
          X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')
          mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) 
          #The emotion label for each audio file is saved in a different portion of the filename for
          #each dataset. Must subset appropriately
          if(dataset_name == 'ravdess'):
            file = file[6:8]
          elif(dataset_name == 'emodb'): 
            file = file[5]
          elif(dataset_name == 'EMOVO'): 
            file = file[0:3]
          elif(dataset_name == 'savee'): 
            #The way the authors formatted this is rather cumbersome.
            #Most emotions are labelled as a single letter in the filename, but some or two letters. Thus we need to do some work.
            if(file[0] == "s"):
              file = file[0:2]
            else:
              file = file[0]
          mask = np.ones(len(mfccs), dtype=bool)
          mask[[2,4,39,38,19]] = False
          arr = mfccs, file
          lst.append(arr)
        # If the file is not valid, skip it
        except ValueError:
          continue

  #pickle if necessary
  if(pickle == 'pickle'):
    with open('list.pkl', 'wb') as f:
      pickle.dump(lst, f)

#load if necessary
if(pickle == 'pickled'):
  f = open(path + 'list.pkl', 'rb')
  lst = pickle.load(f)

X, y = zip(*lst)
X = np.asarray(X)
y = np.asarray(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

#which model to run? defaults to all
model_type = 'all'
if(sys.argv[2] == 'tree'):
  model_type = 'tree'
elif(sys.argv[2] == 'forest'):
  model_type = 'forest'
elif(sys.argv[2] == 'NN'):
  model_type = 'NN'

if(model_type == 'tree'):
  treeModel = DecisionTree(X_train, X_test, y_train, y_test)
  explainTree(treeModel,X)
elif(model_type == 'forest'):
  rfModel = RandomForest(X_train, X_test, y_train, y_test)
  explainTree(rfModel,X)
elif(model_type == 'NN'):
  nnModel, cnnhistory, nnxTest = NueralNetwork(X_train, X_test, y_train, y_test)
  explainNN(nnModel,X_train,X_test)
else: #Else we run all
  treeModel = DecisionTree(X_train, X_test, y_train, y_test)
  rfModel = RandomForest(X_train, X_test, y_train, y_test)
  nnModel, cnnhistory, nnxTest = NueralNetwork(X_train, X_test, y_train, y_test)
  explainTree(treeModel,X)
  explainTree(rfModel,X)
  explainNN(nnModel,X_train,X_test)

plt.plot(cnnhistory.history['loss'])
plt.plot(cnnhistory.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
