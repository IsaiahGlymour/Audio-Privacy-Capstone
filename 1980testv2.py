# -*- coding: utf-8 -*-
"""1980test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12MBDQuFvQSAyfD47checb2mA5UWRFP_i
"""



from google.colab import drive
drive.mount('/content/drive')

!pip install librosa



import librosa
from librosa import display

data, sampling_rate = librosa.load('/content/drive/My Drive/Senior/1980/testAudio.wav')
mfccs = librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40)

import matplotlib.pyplot as plt
import numpy as np
from matplotlib import cm
fig, ax = plt.subplots()

cax = ax.imshow(mfccs, interpolation='nearest', cmap=cm.coolwarm, origin='lower')
ax.set_title('MFCC')

plt.show()

# Commented out IPython magic to ensure Python compatibility.
# % pylab inline
import os
import pandas as pd
import glob

plt.figure(figsize=(12,4))
librosa.display.waveplot(data, sr=sampling_rate)

path = '/content/drive/My Drive/Senior/1980/ravdess'
lst = []

for subdir, dirs, files in os.walk(path):
  for file in files:
      try:
        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array
        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')
        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) 
        file = file[6:8]
        arr = mfccs, file
        lst.append(arr)
      # If the file is not valid, skip it
      except ValueError:
        continue

X, y = zip(*lst)

import numpy as np
X = np.asarray(X)
y = np.asarray(y)


X.shape, y.shape

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

from sklearn.tree import DecisionTreeClassifier

dtree = DecisionTreeClassifier()

dtree.fit(X_train, y_train)

predictions = dtree.predict(X_test)

from sklearn.metrics import classification_report,confusion_matrix
print(classification_report(y_test,predictions))

from sklearn.ensemble import RandomForestClassifier

rforest = RandomForestClassifier(criterion="gini", max_depth=10, max_features="log2", 
                                 max_leaf_nodes = 100, min_samples_leaf = 3, min_samples_split = 20, 
                                 n_estimators= 22000, random_state= 5)

rforest.fit(X_train, y_train)

predictions = rforest.predict(X_test)

print(classification_report(y_test,predictions))

x_traincnn = np.expand_dims(X_train, axis=2)
x_testcnn = np.expand_dims(X_test, axis=2)

x_traincnn.shape, x_testcnn.shape, y_train.shape, y_test.shape

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from matplotlib.pyplot import specgram
import tensorflow.keras
from tensorflow.keras.preprocessing import sequence
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding
from tensorflow.keras.layers import LSTM
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Input, Flatten, Dropout, Activation
from tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.metrics import confusion_matrix

tf.compat.v1.disable_v2_behavior()
tf.compat.v1.disable_eager_execution()

model = Sequential()

model.add(Conv1D(128, 5,padding='same',
                 input_shape=(40,1)))
model.add(Activation('relu'))
model.add(Dropout(0.1))
model.add(MaxPooling1D(pool_size=(8)))
model.add(Conv1D(128, 5,padding='same',))
model.add(Activation('relu'))
model.add(Dropout(0.1))
model.add(Flatten())
model.add(Dense(10))
model.add(Activation('softmax'))
opt = tf.keras.optimizers.RMSprop(learning_rate=0.00005, rho=0.9, epsilon=None, decay=0.0)

model.summary()

model.compile(loss='sparse_categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

y_trainFloat = np.asarray(y_train, dtype=float)
y_testFloat = np.asarray(y_test, dtype=float)
x_traincnnFloat = np.asarray(x_traincnn, dtype=float)
x_testcnnFloat = np.asarray(x_testcnn, dtype=float)

y_train.dtype, y_test.dtype, x_traincnn.dtype, x_testcnn.dtype

y_train.shape, y_test.shape, x_traincnn.shape, x_testcnn.shape

from sklearn import preprocessing

le = preprocessing.LabelEncoder()
le.fit(["01", "02", "03", "04", "05", "06", "07", "08"])
y_train_encoded = le.transform(y_train)
y_test_encoded = le.transform(y_test)

cnnhistory=model.fit(x_traincnn, y_train_encoded, batch_size=16, epochs=100, validation_data=(x_testcnn, y_test_encoded))

predictionsCNN = model.predict(x_testcnn)

predictionsCNN.shape

"""Why does the prediction have 10 dimensions???"""

!pip install shap

import shap as sp

explainer = sp.TreeExplainer(rforest, X_train)

shap_values = np.array(explainer.shap_values(X_test[0])[1])

shap_values

sp.initjs()

explainer2 = sp.TreeExplainer(dtree, X_train)

shap_values2 = np.array(explainer2.shap_values(X_test[0])[1])

shap_values2